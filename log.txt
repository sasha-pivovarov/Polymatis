Optimizer: sgd

Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 32, 22, 22)        320
_________________________________________________________________
activation_1 (Activation)    (None, 32, 22, 22)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 11, 11)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 9, 9)          9248
_________________________________________________________________
activation_2 (Activation)    (None, 32, 9, 9)          0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 4, 4)          0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 64, 2, 2)          18496
_________________________________________________________________
activation_3 (Activation)    (None, 64, 2, 2)          0
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 64, 1, 1)          0
_________________________________________________________________
flatten_1 (Flatten)          (None, 64)                0
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0
_________________________________________________________________
dense_2 (Dense)              (None, 39)                2535
=================================================================
Total params: 34,759
Trainable params: 34,759
Non-trainable params: 0

             precision    recall  f1-score   support

          0       0.91      0.87      0.89        89
          1       0.90      0.93      0.91       120
          2       0.97      0.93      0.95       326
          3       0.92      0.97      0.94        78
          4       0.95      0.97      0.96       315
          5       0.99      0.96      0.97       141
          6       0.94      0.97      0.96       159
          7       0.96      0.97      0.96       202
          8       0.94      0.97      0.95        76
          9       0.98      0.91      0.94        45
         10       0.97      0.93      0.95       392
         11       1.00      0.88      0.94        50
         12       0.92      0.96      0.94       152
         13       1.00      0.97      0.99       170
         14       0.86      0.96      0.91       235
         15       0.95      0.94      0.95       406
         16       0.88      0.95      0.91       106
         17       0.85      0.94      0.90       182
         18       0.94      0.92      0.93       262
         19       0.97      0.95      0.96       260
         20       0.97      0.92      0.95        85
         21       0.00      0.00      0.00         5
         22       1.00      0.94      0.97        48
         23       0.98      0.83      0.90        72
         24       0.98      0.98      0.98        66
         25       0.94      0.94      0.94        49
         26       0.95      0.78      0.86        27
         27       0.96      0.96      0.96       171
         28       0.94      0.96      0.95       275
         29       0.75      0.60      0.67         5
         30       0.94      0.95      0.95       172
         31       0.89      0.98      0.93        41
         32       0.99      0.96      0.97       159
         33       1.00      0.96      0.98        28
         34       0.92      0.98      0.95       130
         35       0.96      0.72      0.83        36
         36       0.00      0.00      0.00         1
         37       0.83      0.83      0.83        18
         38       0.98      0.98      0.98        42

avg / total       0.94      0.94      0.94      5196